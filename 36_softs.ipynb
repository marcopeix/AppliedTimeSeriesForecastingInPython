{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63733ea4-6a63-4eb1-a80d-39c3fa9843c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\neuralforecast-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasetsforecast.long_horizon import LongHorizon\n",
    "\n",
    "from neuralforecast.core import NeuralForecast\n",
    "from neuralforecast.models import NHITS, SOFTS, TSMixer\n",
    "\n",
    "from utilsforecast.losses import mae, mse\n",
    "from utilsforecast.evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84271108-9c8e-4454-9b5e-6b11773f94bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name):\n",
    "    if name == \"ettm1\":\n",
    "        Y_df, *_ = LongHorizon.load(directory='./', group='ETTm1')\n",
    "        Y_df['ds'] = pd.to_datetime(Y_df['ds'])\n",
    "        val_size = 11520\n",
    "        test_size = 11520\n",
    "        freq = '15T'\n",
    "    elif name == \"ettm2\":\n",
    "        Y_df, *_ = LongHorizon.load(directory='./', group='ETTm2')\n",
    "        Y_df['ds'] = pd.to_datetime(Y_df['ds'])\n",
    "        val_size = 11520\n",
    "        test_size = 11520\n",
    "        freq = '15T'\n",
    "    elif name == 'etth1':\n",
    "        Y_df, *_ = LongHorizon.load(directory='./', group='ETTh1')\n",
    "        Y_df['ds'] = pd.to_datetime(Y_df['ds'])\n",
    "        val_size = 2880\n",
    "        test_size = 2880\n",
    "        freq = 'H'\n",
    "    elif name == \"etth2\":\n",
    "        Y_df, *_ = LongHorizon.load(directory='./', group='ETTh2')\n",
    "        Y_df['ds'] = pd.to_datetime(Y_df['ds'])\n",
    "        val_size = 2880\n",
    "        test_size = 2880\n",
    "        freq = 'H'\n",
    "\n",
    "    return Y_df, val_size, test_size, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f8397c-20b4-4613-96f6-60d7a632e472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning_fabric.utilities.seed:Global seed set to 1\n",
      "INFO:lightning_fabric.utilities.seed:Global seed set to 1\n",
      "INFO:lightning_fabric.utilities.seed:Global seed set to 1\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name          | Type                   | Params\n",
      "---------------------------------------------------------\n",
      "0 | loss          | MAE                    | 0     \n",
      "1 | padder        | ConstantPad1d          | 0     \n",
      "2 | scaler        | TemporalNorm           | 0     \n",
      "3 | enc_embedding | DataEmbedding_inverted | 147 K \n",
      "4 | encoder       | TransEncoder           | 4.7 M \n",
      "5 | projection    | Linear                 | 49.2 K\n",
      "---------------------------------------------------------\n",
      "4.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 M     Total params\n",
      "19.708    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|█████████████████| 1/1 [00:00<00:00,  5.65it/s, v_num=54, train_loss_step=0.332, train_loss_epoch=0.355]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 99: 100%|█| 1/1 [00:03<00:00,  3.63s/it, v_num=54, train_loss_step=0.332, train_loss_epoch=0.355, valid_loss=0.42\u001b[A\n",
      "Epoch 199: 100%|█| 1/1 [00:00<00:00,  5.88it/s, v_num=54, train_loss_step=0.352, train_loss_epoch=0.358, valid_loss=0.4\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 199: 100%|█| 1/1 [00:03<00:00,  3.41s/it, v_num=54, train_loss_step=0.352, train_loss_epoch=0.358, valid_loss=0.4\u001b[A\n",
      "Epoch 299: 100%|█| 1/1 [00:00<00:00,  5.68it/s, v_num=54, train_loss_step=0.362, train_loss_epoch=0.329, valid_loss=0.4\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 299: 100%|█| 1/1 [00:03<00:00,  3.44s/it, v_num=54, train_loss_step=0.362, train_loss_epoch=0.329, valid_loss=0.4\u001b[A\n",
      "Epoch 399: 100%|█| 1/1 [00:00<00:00,  5.92it/s, v_num=54, train_loss_step=0.330, train_loss_epoch=0.331, valid_loss=0.4\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 399: 100%|█| 1/1 [00:03<00:00,  3.40s/it, v_num=54, train_loss_step=0.330, train_loss_epoch=0.331, valid_loss=0.4\u001b[A\n",
      "Epoch 499: 100%|█| 1/1 [00:00<00:00,  6.06it/s, v_num=54, train_loss_step=0.315, train_loss_epoch=0.337, valid_loss=0.4\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 499: 100%|█| 1/1 [00:03<00:00,  3.52s/it, v_num=54, train_loss_step=0.315, train_loss_epoch=0.337, valid_loss=0.3\u001b[A\n",
      "Epoch 599: 100%|█| 1/1 [00:00<00:00,  5.43it/s, v_num=54, train_loss_step=0.374, train_loss_epoch=0.337, valid_loss=0.3\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 599: 100%|█| 1/1 [00:03<00:00,  3.48s/it, v_num=54, train_loss_step=0.374, train_loss_epoch=0.337, valid_loss=0.4\u001b[A\n",
      "Epoch 699: 100%|█| 1/1 [00:00<00:00,  5.95it/s, v_num=54, train_loss_step=0.324, train_loss_epoch=0.317, valid_loss=0.4\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 699: 100%|█| 1/1 [00:03<00:00,  3.45s/it, v_num=54, train_loss_step=0.324, train_loss_epoch=0.317, valid_loss=0.4\u001b[A\n",
      "Epoch 799: 100%|█| 1/1 [00:00<00:00,  5.75it/s, v_num=54, train_loss_step=0.307, train_loss_epoch=0.310, valid_loss=0.4\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 799: 100%|█| 1/1 [00:03<00:00,  3.36s/it, v_num=54, train_loss_step=0.307, train_loss_epoch=0.310, valid_loss=0.3\u001b[A\n",
      "Epoch 799: 100%|█| 1/1 [00:03<00:00,  3.37s/it, v_num=54, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=0.3\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name          | Type                     | Params\n",
      "-----------------------------------------------------------\n",
      "0 | loss          | MAE                      | 0     \n",
      "1 | padder        | ConstantPad1d            | 0     \n",
      "2 | scaler        | TemporalNorm             | 0     \n",
      "3 | norm          | ReversibleInstanceNorm1d | 14    \n",
      "4 | mixing_layers | Sequential               | 184 K \n",
      "5 | out           | Linear                   | 27.7 K\n",
      "-----------------------------------------------------------\n",
      "212 K     Trainable params\n",
      "0         Non-trainable params\n",
      "212 K     Total params\n",
      "0.849     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 99: 100%|█████████████████| 1/1 [00:00<00:00,  6.25it/s, v_num=56, train_loss_step=0.366, train_loss_epoch=0.390]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 99: 100%|█| 1/1 [00:01<00:00,  1.61s/it, v_num=56, train_loss_step=0.366, train_loss_epoch=0.390, valid_loss=0.43\u001b[A\n",
      "Epoch 199: 100%|█| 1/1 [00:00<00:00,  6.10it/s, v_num=56, train_loss_step=0.375, train_loss_epoch=0.380, valid_loss=0.4\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 199: 100%|█| 1/1 [00:01<00:00,  1.59s/it, v_num=56, train_loss_step=0.375, train_loss_epoch=0.380, valid_loss=0.4\u001b[A\n",
      "Epoch 299: 100%|█| 1/1 [00:00<00:00,  6.17it/s, v_num=56, train_loss_step=0.400, train_loss_epoch=0.335, valid_loss=0.4\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 299: 100%|█| 1/1 [00:01<00:00,  1.58s/it, v_num=56, train_loss_step=0.400, train_loss_epoch=0.335, valid_loss=0.4\u001b[A\n",
      "Epoch 399: 100%|█| 1/1 [00:00<00:00,  5.59it/s, v_num=56, train_loss_step=0.363, train_loss_epoch=0.361, valid_loss=0.4\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 399: 100%|█| 1/1 [00:01<00:00,  1.60s/it, v_num=56, train_loss_step=0.363, train_loss_epoch=0.361, valid_loss=0.4\u001b[A\n",
      "Epoch 499: 100%|█| 1/1 [00:00<00:00,  5.92it/s, v_num=56, train_loss_step=0.342, train_loss_epoch=0.370, valid_loss=0.4\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 499: 100%|█| 1/1 [00:01<00:00,  1.65s/it, v_num=56, train_loss_step=0.342, train_loss_epoch=0.370, valid_loss=0.4\u001b[A\n",
      "Epoch 599: 100%|█| 1/1 [00:00<00:00,  4.81it/s, v_num=56, train_loss_step=0.433, train_loss_epoch=0.380, valid_loss=0.4\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 599: 100%|█| 1/1 [00:01<00:00,  1.88s/it, v_num=56, train_loss_step=0.433, train_loss_epoch=0.380, valid_loss=0.4\u001b[A\n",
      "Epoch 699: 100%|█| 1/1 [00:00<00:00,  6.25it/s, v_num=56, train_loss_step=0.367, train_loss_epoch=0.340, valid_loss=0.4\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 699: 100%|█| 1/1 [00:01<00:00,  1.56s/it, v_num=56, train_loss_step=0.367, train_loss_epoch=0.340, valid_loss=0.4\u001b[A\n",
      "Epoch 799: 100%|█| 1/1 [00:00<00:00,  5.71it/s, v_num=56, train_loss_step=0.352, train_loss_epoch=0.355, valid_loss=0.4\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 799: 100%|█| 1/1 [00:01<00:00,  1.64s/it, v_num=56, train_loss_step=0.352, train_loss_epoch=0.355, valid_loss=0.4\u001b[A\n",
      "Epoch 899: 100%|█| 1/1 [00:00<00:00,  6.41it/s, v_num=56, train_loss_step=0.354, train_loss_epoch=0.321, valid_loss=0.4\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 899: 100%|█| 1/1 [00:01<00:00,  1.58s/it, v_num=56, train_loss_step=0.354, train_loss_epoch=0.321, valid_loss=0.4\u001b[A\n",
      "Epoch 999: 100%|█| 1/1 [00:00<00:00,  6.41it/s, v_num=56, train_loss_step=0.371, train_loss_epoch=0.325, valid_loss=0.4\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 999: 100%|█| 1/1 [00:01<00:00,  1.57s/it, v_num=56, train_loss_step=0.371, train_loss_epoch=0.325, valid_loss=0.4\u001b[A\n",
      "Epoch 999: 100%|█| 1/1 [00:01<00:00,  1.57s/it, v_num=56, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=0.4\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|█| 1/1 [00:01<00:00,  1.57s/it, v_num=56, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=0.4"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | loss         | MAE           | 0     \n",
      "1 | padder_train | ConstantPad1d | 0     \n",
      "2 | scaler       | TemporalNorm  | 0     \n",
      "3 | blocks       | ModuleList    | 3.2 M \n",
      "-----------------------------------------------\n",
      "3.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 M     Total params\n",
      "12.759    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 99: 100%|█████████████████| 1/1 [00:00<00:00,  1.78it/s, v_num=58, train_loss_step=0.327, train_loss_epoch=0.335]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 99: 100%|█| 1/1 [00:02<00:00,  2.68s/it, v_num=58, train_loss_step=0.327, train_loss_epoch=0.335, valid_loss=0.40\u001b[A\n",
      "Epoch 199: 100%|█| 1/1 [00:00<00:00,  1.99it/s, v_num=58, train_loss_step=0.299, train_loss_epoch=0.314, valid_loss=0.4\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 199: 100%|█| 1/1 [00:02<00:00,  2.60s/it, v_num=58, train_loss_step=0.299, train_loss_epoch=0.314, valid_loss=0.4\u001b[A\n",
      "Epoch 299: 100%|█| 1/1 [00:00<00:00,  2.42it/s, v_num=58, train_loss_step=0.296, train_loss_epoch=0.299, valid_loss=0.4\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 299: 100%|█| 1/1 [00:02<00:00,  2.54s/it, v_num=58, train_loss_step=0.296, train_loss_epoch=0.299, valid_loss=0.4\u001b[A\n",
      "Epoch 399: 100%|█| 1/1 [00:00<00:00,  1.99it/s, v_num=58, train_loss_step=0.284, train_loss_epoch=0.280, valid_loss=0.4\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                   | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 399: 100%|█| 1/1 [00:02<00:00,  2.64s/it, v_num=58, train_loss_step=0.284, train_loss_epoch=0.280, valid_loss=0.4\u001b[A\n",
      "Epoch 399: 100%|█| 1/1 [00:02<00:00,  2.65s/it, v_num=58, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=0.4\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "Y_df, val_size, test_size, freq = load_data('ettm1')\n",
    "\n",
    "horizon = 96\n",
    "\n",
    "models = [\n",
    "    SOFTS(\n",
    "        h=horizon, \n",
    "        input_size=3*horizon, \n",
    "        n_series=7,\n",
    "        hidden_size=512,\n",
    "        d_core=512,\n",
    "        e_layers=2,\n",
    "        d_ff=1024,\n",
    "        use_norm=True,\n",
    "        max_steps=1000, \n",
    "        early_stop_patience_steps=3),\n",
    "    TSMixer(h=horizon, input_size=3*horizon, n_series=7, max_steps=1000, early_stop_patience_steps=3),\n",
    "    NHITS(h=horizon, input_size=3*horizon, max_steps=1000, early_stop_patience_steps=3),\n",
    "]\n",
    "\n",
    "nf = NeuralForecast(models=models, freq=freq)\n",
    "nf_preds = nf.cross_validation(df=Y_df, val_size=val_size, test_size=test_size, n_windows=None)\n",
    "nf_preds = nf_preds.reset_index()\n",
    "\n",
    "ettm1_evaluation = evaluate(df=nf_preds, metrics=[mae, mse], models=['SOFTS', 'TSMixer', 'NHITS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40ec1052-e658-420d-8d68-9c2811f3366e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>SOFTS</th>\n",
       "      <th>TSMixer</th>\n",
       "      <th>NHITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mae</td>\n",
       "      <td>0.345241</td>\n",
       "      <td>0.334170</td>\n",
       "      <td>0.347486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.306944</td>\n",
       "      <td>0.292147</td>\n",
       "      <td>0.317878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric     SOFTS   TSMixer     NHITS\n",
       "0    mae  0.345241  0.334170  0.347486\n",
       "1    mse  0.306944  0.292147  0.317878"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ettm1_evaluation = ettm1_evaluation.drop(['unique_id'], axis=1)\\\n",
    "                                   .groupby('metric')\\\n",
    "                                   .mean()\\\n",
    "                                   .reset_index()\n",
    "\n",
    "ettm1_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac7c8a-85f7-4dcc-a8b3-825a06128159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
